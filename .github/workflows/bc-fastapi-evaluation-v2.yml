# .github/workflows/bc-fastapi-evaluation.yml
# Sistema de evaluaci√≥n autom√°tica para el bootcamp bc-fastapi
# Versi√≥n simplificada y funcional

name: üéØ Evaluaci√≥n bc-fastapi

on:
  repository_dispatch:
    types: [student-submission]
  workflow_dispatch:
    inputs:
      student_repo:
        description: 'Repositorio del estudiante (usuario/repo)'
        required: true
        type: string
      pr_number:
        description: 'N√∫mero del Pull Request'
        required: true
        type: string
      week_number:
        description: 'N√∫mero de semana (1-11)'
        required: false
        type: string
        default: '1'

env:
  PYTHON_VERSION: "3.11"

permissions:
  contents: read
  actions: write

jobs:
  evaluate-submission:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: üì• Checkout repositorio bc-fastapi
      uses: actions/checkout@v4
      with:
        path: bc-fastapi-main
        
    - name: üîç Configurar contexto de evaluaci√≥n
      id: context
      run: |
        if [ "${{ github.event_name }}" = "repository_dispatch" ]; then
          STUDENT_REPO="${{ github.event.client_payload.repository }}"
          PR_NUMBER="${{ github.event.client_payload.pr_number }}"
          WEEK_NUMBER="${{ github.event.client_payload.week_number }}"
        else
          STUDENT_REPO="${{ github.event.inputs.student_repo }}"
          PR_NUMBER="${{ github.event.inputs.pr_number }}"
          WEEK_NUMBER="${{ github.event.inputs.week_number }}"
        fi
        
        STUDENT_NAME=$(echo "$STUDENT_REPO" | cut -d'/' -f1)
        
        echo "student_repo=$STUDENT_REPO" >> $GITHUB_OUTPUT
        echo "student_name=$STUDENT_NAME" >> $GITHUB_OUTPUT
        echo "pr_number=$PR_NUMBER" >> $GITHUB_OUTPUT
        echo "week_number=${WEEK_NUMBER:-1}" >> $GITHUB_OUTPUT
        
        echo "üìä Evaluando: $STUDENT_NAME - Semana ${WEEK_NUMBER:-1}"

    - name: üì• Clonar repositorio del estudiante
      run: |
        STUDENT_REPO="${{ steps.context.outputs.student_repo }}"
        
        echo "üîÑ Clonando repositorio: $STUDENT_REPO"
        git clone "https://github.com/$STUDENT_REPO.git" student-repo || {
          echo "‚ùå Error al clonar repositorio"
          exit 1
        }
        
        echo "‚úÖ Repositorio clonado exitosamente"

    - name: üêç Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: üì¶ Instalar dependencias
      run: |
        pip install --upgrade pip
        pip install fastapi pydantic requests
        echo "‚úÖ Dependencias instaladas"

    - name: üîç Crear script de an√°lisis
      run: |
        cat > analyze_code.py << 'EOF'
        import os
        import json
        import re
        from pathlib import Path
        from datetime import datetime

        def analyze_student_code():
            """Analiza el c√≥digo del estudiante"""
            analysis = {
                "files_analyzed": [],
                "total_lines": 0,
                "functions_count": 0,
                "classes_count": 0,
                "fastapi_usage": False,
                "endpoints_found": [],
                "test_files": [],
                "imports": [],
                "syntax_errors": []
            }
            
            student_path = Path('student-repo')
            if not student_path.exists():
                return analysis
            
            for py_file in student_path.rglob('*.py'):
                if '.git' in str(py_file) or '__pycache__' in str(py_file):
                    continue
                    
                try:
                    with open(py_file, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    analysis["files_analyzed"].append(str(py_file.relative_to(student_path)))
                    lines = [l for l in content.splitlines() if l.strip()]
                    analysis["total_lines"] += len(lines)
                    
                    # Detecta FastAPI
                    if 'fastapi' in content.lower() or 'FastAPI' in content:
                        analysis["fastapi_usage"] = True
                    
                    # Busca endpoints
                    patterns = [
                        r'@app\.(get|post|put|delete|patch)\s*\(\s*["\']([^"\']+)["\']',
                        r'@router\.(get|post|put|delete|patch)\s*\(\s*["\']([^"\']+)["\']'
                    ]
                    
                    for pattern in patterns:
                        matches = re.finditer(pattern, content, re.IGNORECASE)
                        for match in matches:
                            method = match.group(1).upper()
                            path = match.group(2)
                            analysis["endpoints_found"].append(f"{method} {path}")
                    
                    # Cuenta funciones y clases
                    analysis["functions_count"] += len(re.findall(r'^\s*def\s+\w+', content, re.MULTILINE))
                    analysis["classes_count"] += len(re.findall(r'^\s*class\s+\w+', content, re.MULTILINE))
                    
                    # Detecta tests
                    if 'test' in py_file.name.lower() or py_file.name.startswith('test_'):
                        analysis["test_files"].append(str(py_file.relative_to(student_path)))
                        
                except Exception as e:
                    analysis["syntax_errors"].append(f"{py_file.name}: {str(e)}")
            
            return analysis

        def calculate_score(analysis, week_number):
            """Calcula puntuaci√≥n basada en criterios"""
            score = 0
            feedback = []
            improvements = []
            
            # Criterio 1: Entrega de archivos (20 pts)
            files_count = len(analysis['files_analyzed'])
            if files_count > 0:
                score += 20
                feedback.append(f"‚úÖ {files_count} archivos Python entregados")
            else:
                improvements.append("‚ùå No se encontraron archivos Python")
            
            # Criterio 2: Uso de FastAPI (30 pts)
            if analysis['fastapi_usage']:
                score += 30
                feedback.append("‚úÖ FastAPI implementado correctamente")
            else:
                improvements.append("‚ö†Ô∏è FastAPI no detectado - Verificar importaciones")
            
            # Criterio 3: Endpoints (25 pts)
            endpoints_count = len(analysis['endpoints_found'])
            if endpoints_count >= 3:
                score += 25
                feedback.append(f"‚úÖ {endpoints_count} endpoints implementados")
            elif endpoints_count > 0:
                score += 15
                feedback.append(f"‚ö†Ô∏è Solo {endpoints_count} endpoints encontrados")
                improvements.append("Implementar m√°s endpoints seg√∫n requisitos")
            else:
                improvements.append("‚ùå No se encontraron endpoints")
            
            # Criterio 4: Calidad del c√≥digo (25 pts)
            total_lines = analysis['total_lines']
            if total_lines >= 100:
                score += 25
                feedback.append("‚úÖ C√≥digo bien desarrollado")
            elif total_lines >= 50:
                score += 20
                feedback.append("‚úÖ Implementaci√≥n b√°sica completa")
            elif total_lines >= 20:
                score += 15
                feedback.append("‚ö†Ô∏è Implementaci√≥n m√≠nima")
            else:
                improvements.append("‚ùå C√≥digo insuficiente - Expandir implementaci√≥n")
            
            # Bonus por modularizaci√≥n
            if analysis['functions_count'] >= 5:
                score += 5
                feedback.append("‚úÖ Buena modularizaci√≥n con funciones")
            
            # Determina categor√≠a
            if score >= 90:
                category = "Excelente"
                emoji = "üèÜ"
            elif score >= 80:
                category = "Satisfactorio" 
                emoji = "‚úÖ"
            elif score >= 70:
                category = "Necesita Mejora"
                emoji = "‚ö†Ô∏è"
            else:
                category = "Insuficiente"
                emoji = "‚ùå"
            
            return score, category, emoji, feedback, improvements

        def generate_report(student_name, week_number, analysis, score, category, emoji, feedback, improvements):
            """Genera el reporte de evaluaci√≥n"""
            
            report = f"""# üéØ Evaluaci√≥n Autom√°tica bc-fastapi

**Estudiante:** {student_name}  
**Semana:** {week_number}  
**Fecha:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  

---

## {emoji} Calificaci√≥n: {score}/100 puntos ({category})

### ‚úÖ Fortalezas Identificadas:
"""
            
            for point in feedback:
                report += f"- {point}\n"
            
            if improvements:
                report += "\n### üéØ √Åreas de Mejora:\n"
                for improvement in improvements:
                    report += f"- {improvement}\n"
            
            # An√°lisis t√©cnico
            report += f"""
### üìä An√°lisis T√©cnico:
- **Archivos analizados:** {len(analysis['files_analyzed'])}
- **L√≠neas de c√≥digo:** {analysis['total_lines']}
- **Funciones encontradas:** {analysis['functions_count']}
- **Clases encontradas:** {analysis['classes_count']}
- **FastAPI detectado:** {'‚úÖ S√≠' if analysis['fastapi_usage'] else '‚ùå No'}
- **Endpoints implementados:** {len(analysis['endpoints_found'])}
"""
            
            if analysis['endpoints_found']:
                report += "\n#### Endpoints encontrados:\n"
                for endpoint in analysis['endpoints_found']:
                    report += f"- `{endpoint}`\n"
            
            if analysis['test_files']:
                report += f"\n#### Archivos de test: {len(analysis['test_files'])}\n"
                for test_file in analysis['test_files']:
                    report += f"- `{test_file}`\n"
            
            # Pr√≥ximos pasos
            next_week = int(week_number) + 1
            if next_week <= 11:
                report += f"""
### üìö Pr√≥ximos Pasos para Semana {next_week}:
- Revisa el material de la semana {next_week} en el repositorio principal
- Implementa las mejoras sugeridas si las hay
- Participa en las discusiones del curso para resolver dudas
"""
            else:
                report += """
### üéì ¬°Bootcamp Completado!
- Revisa el feedback final del proyecto
- Prepara tu portafolio con los proyectos desarrollados
- ¬°Felicidades por completar el bootcamp bc-fastapi!
"""
            
            # Recursos y contacto
            report += f"""
### üìû Recursos de Apoyo:
- **Repositorio principal:** https://github.com/elparchetipk/bc-fastapi
- **Material de la semana:** `/semana-{week_number:02d}/`
- **Documentaci√≥n:** `/_docs/`
- **Instructor:** Erick Granados Torres - SENA CGMLTI

---

## ü§ñ Informaci√≥n de la Evaluaci√≥n

- **Sistema:** Evaluaci√≥n autom√°tica bc-fastapi v2.0
- **Algoritmo:** An√°lisis est√°tico + Validaci√≥n de patrones FastAPI
- **Generado:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")} 

---

*Sistema desarrollado para el bootcamp bc-fastapi - SENA Regional Distrito Capital*
"""
            
            return report

        def main():
            # Obtiene par√°metros del entorno
            student_name = os.getenv('STUDENT_NAME', 'Estudiante')
            week_number = os.getenv('WEEK_NUMBER', '1')
            
            print(f"üöÄ Iniciando evaluaci√≥n para {student_name} - Semana {week_number}")
            
            # Analiza c√≥digo
            analysis = analyze_student_code()
            print(f"üìä Archivos analizados: {len(analysis['files_analyzed'])}")
            
            if len(analysis['files_analyzed']) == 0:
                # Sin c√≥digo para evaluar
                report = f"""# ‚ö†Ô∏è Sin c√≥digo para evaluar

**Estudiante:** {student_name}  
**Semana:** {week_number}  
**Fecha:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## Problema Detectado

No se encontraron archivos Python (.py) en tu repositorio para evaluar.

### üîç Verifica lo siguiente:
1. ‚úÖ Tu c√≥digo est√° en archivos .py
2. ‚úÖ Los archivos est√°n en la rama correcta
3. ‚úÖ El repositorio es p√∫blico o el sistema tiene acceso
4. ‚úÖ No hay errores de permisos

### üìû Obtener Ayuda:
- Revisa las instrucciones de entrega en el repositorio principal
- Contacta al instructor si persiste el problema
- Verifica que tu Pull Request est√© correctamente creado

---
ü§ñ *Evaluaci√≥n autom√°tica bc-fastapi*
"""
            else:
                # Eval√∫a c√≥digo encontrado
                score, category, emoji, feedback, improvements = calculate_score(analysis, int(week_number))
                report = generate_report(student_name, week_number, analysis, score, category, emoji, feedback, improvements)
                print(f"‚úÖ Evaluaci√≥n completada: {score}/100 ({category})")
            
            # Guarda reporte
            with open('evaluation_report.md', 'w', encoding='utf-8') as f:
                f.write(report)
            
            # Guarda an√°lisis en JSON
            analysis['evaluation_score'] = score if 'score' in locals() else 0
            analysis['evaluation_category'] = category if 'category' in locals() else 'Sin C√≥digo'
            
            with open('analysis_result.json', 'w', encoding='utf-8') as f:
                json.dump(analysis, f, indent=2, ensure_ascii=False)
            
            print("üíæ Reporte guardado exitosamente")

        if __name__ == "__main__":
            main()
        EOF

    - name: üîç Ejecutar an√°lisis y evaluaci√≥n
      run: |
        python analyze_code.py
      env:
        STUDENT_NAME: ${{ steps.context.outputs.student_name }}
        WEEK_NUMBER: ${{ steps.context.outputs.week_number }}

    - name: üìä Mostrar resumen
      run: |
        echo "üéØ RESUMEN DE EVALUACI√ìN"
        echo "========================"
        echo "üë§ Estudiante: ${{ steps.context.outputs.student_name }}"
        echo "üìÖ Semana: ${{ steps.context.outputs.week_number }}"
        echo "üîó Repositorio: ${{ steps.context.outputs.student_repo }}"
        echo ""
        
        if [ -f "evaluation_report.md" ]; then
          echo "‚úÖ Evaluaci√≥n completada"
          
          # Extrae puntuaci√≥n del reporte
          if grep -q "Calificaci√≥n:" evaluation_report.md; then
            SCORE_LINE=$(grep "Calificaci√≥n:" evaluation_report.md)
            echo "üìä $SCORE_LINE"
          fi
          
          # Muestra primeras l√≠neas del an√°lisis t√©cnico
          echo ""
          echo "üìã AN√ÅLISIS T√âCNICO:"
          if [ -f "analysis_result.json" ]; then
            python -c "
import json
with open('analysis_result.json', 'r') as f:
    data = json.load(f)
print(f'   üìÑ Archivos: {len(data.get(\"files_analyzed\", []))}')
print(f'   üìè L√≠neas: {data.get(\"total_lines\", 0)}')
print(f'   üöÄ FastAPI: {\"S√≠\" if data.get(\"fastapi_usage\", False) else \"No\"}')
print(f'   üéØ Endpoints: {len(data.get(\"endpoints_found\", []))}')
            "
          fi
        else
          echo "‚ùå Error en la evaluaci√≥n - No se gener√≥ reporte"
          exit 1
        fi

    - name: üì§ Subir resultados como artifacts
      uses: actions/upload-artifact@v4
      with:
        name: evaluation-results-${{ steps.context.outputs.student_name }}-week-${{ steps.context.outputs.week_number }}
        path: |
          evaluation_report.md
          analysis_result.json
        retention-days: 90

    - name: ‚úÖ Evaluaci√≥n completada
      run: |
        echo "üéâ EVALUACI√ìN FINALIZADA"
        echo "========================"
        echo "‚úÖ Reporte generado: evaluation_report.md"
        echo "‚úÖ An√°lisis t√©cnico: analysis_result.json" 
        echo "‚úÖ Artifacts subidos para revisi√≥n"
        echo ""
        echo "üìû Los resultados est√°n disponibles en los artifacts de este workflow"
        echo "üîó URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

  # Job opcional para crear issue (requiere configuraci√≥n adicional)
  create-feedback-issue:
    needs: evaluate-submission
    if: ${{ success() && vars.CREATE_FEEDBACK_ISSUES == 'true' && secrets.GITHUB_TOKEN != '' }}
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    steps:
    - name: ‚¨áÔ∏è Descargar resultados de evaluaci√≥n
      uses: actions/download-artifact@v4
      with:
        name: evaluation-results-${{ needs.evaluate-submission.steps.context.outputs.student_name }}-week-${{ needs.evaluate-submission.steps.context.outputs.week_number }}

    - name: üìù Crear issue de feedback (si est√° configurado)
      uses: actions/github-script@v7
      env:
        STUDENT_REPO: ${{ needs.evaluate-submission.steps.context.outputs.student_repo }}
        WEEK_NUMBER: ${{ needs.evaluate-submission.steps.context.outputs.week_number }}
      with:
        github-token: ${{ secrets.STUDENT_REPOS_TOKEN || secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');
          
          try {
            if (!fs.existsSync('evaluation_report.md')) {
              console.log('‚ùå No se encontr√≥ el reporte de evaluaci√≥n');
              return;
            }
            
            const evaluation = fs.readFileSync('evaluation_report.md', 'utf8');
            const studentRepo = process.env.STUDENT_REPO;
            const weekNumber = process.env.WEEK_NUMBER;
            
            if (!studentRepo || !studentRepo.includes('/')) {
              console.log('‚ö†Ô∏è Formato de repositorio inv√°lido');
              return;
            }
            
            const [owner, repo] = studentRepo.split('/');
            
            const issueBody = evaluation + `

---

## üéØ Acciones Recomendadas

### ‚úÖ Si tu calificaci√≥n fue satisfactoria o excelente:
- üéâ ¬°Felicidades! Contin√∫a con la siguiente semana
- üìö Revisa las sugerencias de mejora para optimizar tu c√≥digo
- ü§ù Ayuda a compa√±eros en las discusiones del bootcamp

### üîÑ Si necesitas mejoras:
- üìñ Implementa las correcciones sugeridas arriba
- üíª Revisa el material de la semana en el repositorio principal
- üí¨ Comenta en este issue si tienes dudas espec√≠ficas

---

ü§ñ *Issue creado autom√°ticamente por el sistema bc-fastapi*  
üìÖ *Fecha: ${new Date().toLocaleDateString('es-CO')}*
`;

            const issue = await github.rest.issues.create({
              owner: owner,
              repo: repo,
              title: `üìã Evaluaci√≥n Semana ${weekNumber} - Feedback Autom√°tico`,
              body: issueBody,
              labels: ['evaluacion-automatica', `semana-${weekNumber}`, 'bc-fastapi']
            });
            
            console.log(`‚úÖ Issue de feedback creado: ${issue.data.html_url}`);
            
          } catch (error) {
            console.log(`‚ö†Ô∏è No se pudo crear el issue: ${error.message}`);
            console.log('Esto es normal si no tienes permisos configurados');
          }
